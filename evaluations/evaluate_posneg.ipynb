{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from analysis.probability import simple_posneg as probability_generator\n",
    "from evaluate import evaluate_single\n",
    "\n",
    "def eval_simple(note):\n",
    "    return evaluate_single(probability_generator(note), root_note=note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from analysis.musical import consonance_ordered_notes, empirical_probabilities\n",
    "from analysis.spike_tensor import generate_spike_tensor\n",
    "from cache import get_spikes\n",
    "from evaluate import predicted_consonance_scores, predicted_probabilities\n",
    "\n",
    "root_note = \"C4\"\n",
    "notes = consonance_ordered_notes(root_note)\n",
    "notes_spikes = [get_spikes(note) for note in notes]\n",
    "consonance_ordered_tensors = [generate_spike_tensor(spikes) for spikes in notes_spikes]\n",
    "\n",
    "root_tensor = generate_spike_tensor(get_spikes(root_note))\n",
    "probability_tensor = probability_generator(root_note)\n",
    "\n",
    "def try_eval(tensors, metric, debug=False):\n",
    "    scores = predicted_consonance_scores(probability_tensor, tensors, root_tensor)\n",
    "\n",
    "    P_predicted = predicted_probabilities(scores)\n",
    "\n",
    "    if debug:\n",
    "        def print_arr(arr):\n",
    "            print(np.round(np.array(arr), 3))\n",
    "        print(\"Scores\")\n",
    "        print_arr(scores)\n",
    "        print(\"P_predicted\")\n",
    "        print_arr(P_predicted)\n",
    "        print(\"P_empirical\")\n",
    "        print_arr(empirical_probabilities())\n",
    "\n",
    "    print(metric(P_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[-0.615 -0.687 -0.689 -0.695 -0.696 -0.666 -0.688 -0.67  -0.672 -0.649\n",
      " -0.689 -0.678]\n",
      "P_predicted\n",
      "[0.312 0.036 0.03  0.004 0.    0.114 0.032 0.1   0.095 0.18  0.028 0.069]\n",
      "P_empirical\n",
      "[0.147 0.133 0.12  0.107 0.107 0.093 0.08  0.067 0.053 0.053 0.027 0.013]\n",
      "0.3869871813546658\n"
     ]
    }
   ],
   "source": [
    "from evaluate import js_divergence\n",
    "\n",
    "try_eval(consonance_ordered_tensors, js_divergence, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def shuffle_attempts(metric, N=10):\n",
    "    data = []\n",
    "    for i in range(N):\n",
    "        A = consonance_ordered_tensors[0][0][0]\n",
    "        np.random.shuffle(consonance_ordered_tensors)\n",
    "        B = consonance_ordered_tensors[0][0][0]\n",
    "        if not np.array_equal(A, B):\n",
    "            value = try_eval(consonance_ordered_tensors, metric)\n",
    "            data.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38660410674711476\n",
      "0.3626837146922029\n",
      "0.3336491446707358\n",
      "0.427786582941451\n",
      "0.4461984739198874\n",
      "0.3782307454264301\n",
      "0.40558715988552435\n",
      "0.45475612420380324\n",
      "0.36494136741310074\n"
     ]
    }
   ],
   "source": [
    "from evaluate import js_divergence\n",
    "\n",
    "shuffle_attempts(js_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[-0.615 -0.678 -1.268]\n",
      "P_predicted\n",
      "[0.53 0.47 0.  ]\n",
      "Most Cons, Least Cons, White Noise\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from cache import SPIKES_DIR\n",
    "\n",
    "\n",
    "root_note = \"C4\"\n",
    "notes = consonance_ordered_notes(root_note)\n",
    "notes = [notes[0], notes[-1]]\n",
    "notes_spikes = [get_spikes(note) for note in notes]\n",
    "tensors = [generate_spike_tensor(spikes) for spikes in notes_spikes]\n",
    "\n",
    "white_noise_spikes = np.load(os.path.join(SPIKES_DIR, \"white_noise.npy\"))\n",
    "tensors.append(generate_spike_tensor(white_noise_spikes))\n",
    "\n",
    "root_tensor = generate_spike_tensor(get_spikes(root_note))\n",
    "\n",
    "scores = predicted_consonance_scores(probability_tensor, tensors, root_tensor)\n",
    "print(\"Scores\")\n",
    "print(np.round(np.array(scores), 3))\n",
    "\n",
    "P_predicted = predicted_probabilities(scores)\n",
    "print(\"P_predicted\")\n",
    "print(np.round(np.array(P_predicted), 2))\n",
    "\n",
    "print(\"Most Cons, Least Cons, White Noise\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4: 61\n",
      "C#4: 55\n",
      "D4: 59\n",
      "D#4: 59\n",
      "E4: 68\n",
      "F4: 61\n",
      "F#4: 64\n",
      "G4: 70\n",
      "G#4: 69\n",
      "A4: 70\n",
      "A#4: 62\n",
      "B4: 75\n"
     ]
    }
   ],
   "source": [
    "keys = [\"C4\", \"C#4\", \"D4\", \"D#4\", \"E4\", \"F4\", \"F#4\", \"G4\", \"G#4\", \"A4\", \"A#4\", \"B4\"]\n",
    "\n",
    "for key in keys:\n",
    "    print(f\"{key}: {eval_simple(key)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C5', 'G4', 'F4', 'E4', 'D#4', 'A4', 'G#4', 'D4', 'C#4', 'B4', 'A#4', 'F#4']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consonance_ordered_notes(root_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect_data(kl_divergence_reverse)\n",
    "# collect_data(kl_divergence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
