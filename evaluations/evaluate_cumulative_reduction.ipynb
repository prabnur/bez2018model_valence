{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from analysis.probability import cumulative_reduction_optimized\n",
    "from evaluate import evaluate_single\n",
    "\n",
    "probability_generator = cumulative_reduction_optimized\n",
    "tau = 0.001\n",
    "\n",
    "def eval_simple(note):\n",
    "    return evaluate_single(probability_generator(note), tau=tau,root_note=note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from analysis.musical import consonance_ordered_notes, empirical_probabilities\n",
    "from analysis.spike_tensor import generate_spike_tensor\n",
    "from cache import get_spikes\n",
    "from evaluate import predicted_consonance_scores, predicted_probabilities\n",
    "\n",
    "root_note = \"C4\"\n",
    "notes = consonance_ordered_notes(root_note)\n",
    "notes_spikes = [get_spikes(note) for note in notes]\n",
    "consonance_ordered_tensors = [generate_spike_tensor(spikes, tau=tau) for spikes in notes_spikes]\n",
    "\n",
    "root_tensor = generate_spike_tensor(get_spikes(root_note), tau=tau)\n",
    "probability_tensor = probability_generator(root_note)\n",
    "\n",
    "def try_eval(tensors, metric, debug=False):\n",
    "    scores = predicted_consonance_scores(probability_tensor, tensors, root_tensor)\n",
    "\n",
    "    P_predicted = predicted_probabilities(scores)\n",
    "\n",
    "    if debug:\n",
    "        def print_arr(arr):\n",
    "            print(np.round(np.array(arr), 3))\n",
    "        print(\"Scores\")\n",
    "        print_arr(scores)\n",
    "        print(\"P_predicted\")\n",
    "        print_arr(P_predicted)\n",
    "        print(\"P_empirical\")\n",
    "        print_arr(empirical_probabilities())\n",
    "\n",
    "    print(metric(P_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[-15.783 -17.773 -17.825 -17.993 -18.001 -17.164 -17.701 -17.398 -17.375\n",
      " -16.647 -17.735 -17.539]\n",
      "P_predicted\n",
      "[0.313 0.032 0.025 0.001 0.    0.118 0.042 0.085 0.088 0.191 0.038 0.065]\n",
      "P_empirical\n",
      "[0.147 0.133 0.12  0.107 0.107 0.093 0.08  0.067 0.053 0.053 0.027 0.013]\n",
      "0.3965227436078749\n"
     ]
    }
   ],
   "source": [
    "from doctest import debug\n",
    "from evaluate import js_divergence\n",
    "\n",
    "\n",
    "try_eval(consonance_ordered_tensors, js_divergence, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def shuffle_attempts(metric, N=10):\n",
    "    data = []\n",
    "    for i in range(N):\n",
    "        A = consonance_ordered_tensors[0][0][0]\n",
    "        np.random.shuffle(consonance_ordered_tensors)\n",
    "        B = consonance_ordered_tensors[0][0][0]\n",
    "        if not np.array_equal(A, B):\n",
    "            value = try_eval(consonance_ordered_tensors, metric)\n",
    "            data.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39343818680536624\n",
      "0.3287912589177932\n",
      "0.3438795071251344\n",
      "0.32299800889466834\n",
      "0.4042231037835214\n",
      "0.30842111553758833\n",
      "0.4504984410785446\n",
      "0.3653716826364866\n",
      "0.4591172169691094\n"
     ]
    }
   ],
   "source": [
    "from evaluate import js_divergence\n",
    "\n",
    "\n",
    "shuffle_attempts(js_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[-16. -18. -31.]\n",
      "P_predicted\n",
      "[0.53 0.47 0.  ]\n",
      "Most Cons, Least Cons, White Noise\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from cache import SPIKES_DIR\n",
    "\n",
    "\n",
    "root_note = \"C4\"\n",
    "notes = consonance_ordered_notes(root_note)\n",
    "notes = [notes[0], notes[-1]]\n",
    "notes_spikes = [get_spikes(note) for note in notes]\n",
    "tensors = [generate_spike_tensor(spikes, tau=tau) for spikes in notes_spikes]\n",
    "\n",
    "white_noise_spikes = np.load(os.path.join(SPIKES_DIR, \"white_noise.npy\"))\n",
    "tensors.append(generate_spike_tensor(white_noise_spikes, tau=tau))\n",
    "\n",
    "root_tensor = generate_spike_tensor(get_spikes(root_note), tau=tau)\n",
    "\n",
    "scores = predicted_consonance_scores(probability_tensor, tensors, root_tensor)\n",
    "print(\"Scores\")\n",
    "print(np.round(np.array(scores)))\n",
    "\n",
    "P_predicted = predicted_probabilities(scores)\n",
    "print(\"P_predicted\")\n",
    "print(np.round(np.array(P_predicted), 2))\n",
    "\n",
    "print(\"Most Cons, Least Cons, White Noise\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4: 60\n",
      "C#4: 58\n",
      "D4: 60\n",
      "D#4: 63\n",
      "E4: 65\n",
      "F4: 58\n",
      "F#4: 61\n",
      "G4: 70\n",
      "G#4: 69\n",
      "A4: 71\n",
      "A#4: 61\n",
      "B4: 75\n"
     ]
    }
   ],
   "source": [
    "keys = [\"C4\", \"C#4\", \"D4\", \"D#4\", \"E4\", \"F4\", \"F#4\", \"G4\", \"G#4\", \"A4\", \"A#4\", \"B4\"]\n",
    "\n",
    "for key in keys:\n",
    "    print(f\"{key}: {eval_simple(key)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C5', 'G4', 'F4', 'E4', 'D#4', 'A4', 'G#4', 'D4', 'C#4', 'B4', 'A#4', 'F#4']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consonance_ordered_notes(root_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle_attempts(kl_divergence_reverse)\n",
    "# shuffle_attempts(kl_divergence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
