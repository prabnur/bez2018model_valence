{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from analysis.probability import generate_probabilities_simple as probability_generator\n",
    "from evaluate import evaluate_single\n",
    "\n",
    "def eval_simple(note):\n",
    "    return evaluate_single(probability_generator(note), root_note=note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from analysis.musical import consonance_ordered_notes, empirical_probabilities\n",
    "from analysis.spike_tensor import generate_spike_tensor\n",
    "from cache import get_spikes\n",
    "from evaluate import predicted_consonance_scores, predicted_probabilities\n",
    "\n",
    "root_note = \"C4\"\n",
    "notes = consonance_ordered_notes(root_note)\n",
    "notes_spikes = [get_spikes(note) for note in notes]\n",
    "consonance_ordered_tensors = [generate_spike_tensor(spikes) for spikes in notes_spikes]\n",
    "\n",
    "root_tensor = generate_spike_tensor(get_spikes(root_note))\n",
    "probability_tensor = probability_generator(root_note)\n",
    "\n",
    "def try_eval(tensors, metric, debug=False):\n",
    "    scores = predicted_consonance_scores(probability_tensor, tensors, root_tensor)\n",
    "\n",
    "    P_predicted = predicted_probabilities(scores)\n",
    "\n",
    "    if debug:\n",
    "        def print_arr(arr):\n",
    "            print(np.round(np.array(arr), 3))\n",
    "        print(\"Scores\")\n",
    "        print_arr(scores)\n",
    "        print(\"P_predicted\")\n",
    "        print_arr(P_predicted)\n",
    "        print(\"P_empirical\")\n",
    "        print_arr(empirical_probabilities())\n",
    "\n",
    "    print(metric(P_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[0.119 0.135 0.135 0.136 0.135 0.129 0.132 0.134 0.133 0.124 0.131 0.132]\n",
      "P_predicted\n",
      "[0.076 0.086 0.086 0.086 0.086 0.082 0.084 0.085 0.084 0.079 0.083 0.084]\n",
      "P_empirical\n",
      "[0.147 0.133 0.12  0.107 0.107 0.093 0.08  0.067 0.053 0.053 0.027 0.013]\n",
      "0.1912142431741392\n"
     ]
    }
   ],
   "source": [
    "from evaluate import js_divergence\n",
    "\n",
    "try_eval(consonance_ordered_tensors, js_divergence, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def collect_data(metric, N=10):\n",
    "    data = []\n",
    "    for i in range(N):\n",
    "        A = consonance_ordered_tensors[0][0][0]\n",
    "        np.random.shuffle(consonance_ordered_tensors)\n",
    "        B = consonance_ordered_tensors[0][0][0]\n",
    "        if not np.array_equal(A, B):\n",
    "            value = try_eval(consonance_ordered_tensors, metric)\n",
    "            data.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1867308508607451\n",
      "0.1869592441086574\n",
      "0.18455535602690212\n",
      "0.191067307810729\n",
      "0.19576684114843682\n",
      "0.1922930766126963\n",
      "0.19469856689203893\n",
      "0.19180309122740768\n"
     ]
    }
   ],
   "source": [
    "from evaluate import js_divergence\n",
    "\n",
    "collect_data(js_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[0. 0. 0.]\n",
      "P_predicted\n",
      "[0.29 0.33 0.38]\n",
      "Most Cons, Least Cons, White Noise\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from cache import SPIKES_DIR\n",
    "\n",
    "\n",
    "root_note = \"C4\"\n",
    "notes = consonance_ordered_notes(root_note)\n",
    "notes = [notes[0], notes[-1]]\n",
    "notes_spikes = [get_spikes(note) for note in notes]\n",
    "tensors = [generate_spike_tensor(spikes) for spikes in notes_spikes]\n",
    "\n",
    "white_noise_spikes = np.load(os.path.join(SPIKES_DIR, \"white_noise.npy\"))\n",
    "tensors.append(generate_spike_tensor(white_noise_spikes))\n",
    "\n",
    "root_tensor = generate_spike_tensor(get_spikes(root_note))\n",
    "\n",
    "scores = predicted_consonance_scores(probability_tensor, tensors, root_tensor)\n",
    "print(\"Scores\")\n",
    "print(np.round(np.array(scores)))\n",
    "\n",
    "P_predicted = predicted_probabilities(scores)\n",
    "print(\"P_predicted\")\n",
    "print(np.round(np.array(P_predicted), 2))\n",
    "\n",
    "print(\"Most Cons, Least Cons, White Noise\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4: 81\n",
      "C#4: 81\n",
      "D4: 81\n",
      "D#4: 81\n",
      "E4: 81\n",
      "F4: 81\n",
      "F#4: 81\n",
      "G4: 80\n",
      "G#4: 81\n",
      "A4: 81\n",
      "A#4: 81\n",
      "B4: 80\n"
     ]
    }
   ],
   "source": [
    "keys = [\"C4\", \"C#4\", \"D4\", \"D#4\", \"E4\", \"F4\", \"F#4\", \"G4\", \"G#4\", \"A4\", \"A#4\", \"B4\"]\n",
    "\n",
    "for key in keys:\n",
    "    print(f\"{key}: {eval_simple(key)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C5', 'G4', 'F4', 'E4', 'D#4', 'A4', 'G#4', 'D4', 'C#4', 'B4', 'A#4', 'F#4']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consonance_ordered_notes(root_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect_data(kl_divergence_reverse)\n",
    "# collect_data(kl_divergence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
